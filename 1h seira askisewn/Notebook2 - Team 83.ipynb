{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Section 2\n",
    "\n",
    "## Efstathios Galanakis 03112172\n",
    "## Ioannis Tzanettis 03112506\n",
    "## Team Number: 83\n",
    "\n",
    "\n",
    "\n",
    "Datasheet Name: SECOM\n",
    "Number of features: 1567\n",
    "Number of classes: 591\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "# Insert Data\n",
    "\n",
    "First we read data from file and we separate train data from test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  1. ...,  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "perc = 0.3\n",
    "k = 5\n",
    "\n",
    "features = []\n",
    "labels = []\n",
    "\n",
    "labels_path = './big/secom_labels.data'\n",
    "datasheet_labels = pd.read_csv(labels_path, header=None, delim_whitespace=True)\n",
    "mapping={-1:0}\n",
    "labels = datasheet_labels.replace(mapping).values[:,0].flatten()\n",
    "labels = np.float64(labels)\n",
    "print labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "After reading we have to replace missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.03093000e+03   2.56400000e+03   2.18773330e+03 ...,   1.64749042e-02\n",
      "    5.28333333e-03   9.96700663e+01]\n",
      " [  3.09578000e+03   2.46514000e+03   2.23042220e+03 ...,   2.01000000e-02\n",
      "    6.00000000e-03   2.08204500e+02]\n",
      " [  2.93261000e+03   2.55994000e+03   2.18641110e+03 ...,   4.84000000e-02\n",
      "    1.48000000e-02   8.28602000e+01]\n",
      " ..., \n",
      " [  2.97881000e+03   2.37978000e+03   2.20630000e+03 ...,   8.60000000e-03\n",
      "    2.50000000e-03   4.35231000e+01]\n",
      " [  2.89492000e+03   2.53201000e+03   2.17703330e+03 ...,   2.45000000e-02\n",
      "    7.50000000e-03   9.34941000e+01]\n",
      " [  2.94492000e+03   2.45076000e+03   2.19544440e+03 ...,   1.62000000e-02\n",
      "    4.50000000e-03   1.37784400e+02]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "\n",
    "features_path = './big/secom.data'\n",
    "datasheet_features = pd.read_csv(features_path, header=None, delim_whitespace=True)\n",
    "features = imp.fit_transform(datasheet_features)\n",
    "print features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "After we replace the missing value, it's time to seperate train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1567, 590) (1567,)\n",
      "(1096, 590) (471, 590) (1096,) (471,)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(features,labels,test_size=perc)\n",
    "y_train = y_train.ravel()\n",
    "print  features.shape, labels.shape\n",
    "print x_train.shape, x_test.shape, y_train.shape, y_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Preprocessing\n",
    "### Feature selection\n",
    "We use VarianceThreshold in order to remove features that remain steady for all the samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1096, 367)\n",
      "(471, 367)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "selector = VarianceThreshold(0.001)\n",
    "reduced_train_data = selector.fit_transform(x_train)\n",
    "print reduced_train_data.shape\n",
    "\n",
    "selected_features = selector.get_support()\n",
    "reduced_test_data = x_test[:,selected_features]\n",
    "\n",
    "print reduced_test_data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
       "       beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
       "       hidden_layer_sizes=(100,), learning_rate='constant',\n",
       "       learning_rate_init=0.001, max_iter=200, momentum=0.9,\n",
       "       nesterovs_momentum=True, power_t=0.5, random_state=None,\n",
       "       shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "       verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy_clf = MLPClassifier();\n",
    "dummy_clf.fit(x_train, y_train.astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Feature Scaling\n",
    "We transform our train data according to the standard score given by:$$z = {X- \\mu \\over \\sigma}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'std_train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-884bd74c7477>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mscaled_train_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0mstd_train_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduced_train_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'std_train_data' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "scaled_train_data = preprocessing.scale(reduced_train_data)\n",
    "print std_train_data\n",
    "print \"\"\n",
    "scaler = preprocessing.StandardScaler().fit(reduced_train_data)\n",
    "scaled_test_data = scaler.transform(reduced_test_data)\n",
    "print scaled_test_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  3.03093000e+03   2.56400000e+03   2.18773330e+03 ...,   1.64749042e-02\n",
      "    5.28333333e-03   9.96700663e+01]\n",
      " [  3.09578000e+03   2.46514000e+03   2.23042220e+03 ...,   2.01000000e-02\n",
      "    6.00000000e-03   2.08204500e+02]\n",
      " [  2.93261000e+03   2.55994000e+03   2.18641110e+03 ...,   4.84000000e-02\n",
      "    1.48000000e-02   8.28602000e+01]\n",
      " ..., \n",
      " [  2.97881000e+03   2.37978000e+03   2.20630000e+03 ...,   8.60000000e-03\n",
      "    2.50000000e-03   4.35231000e+01]\n",
      " [  2.89492000e+03   2.53201000e+03   2.17703330e+03 ...,   2.45000000e-02\n",
      "    7.50000000e-03   9.34941000e+01]\n",
      " [  2.94492000e+03   2.45076000e+03   2.19544440e+03 ...,   1.62000000e-02\n",
      "    4.50000000e-03   1.37784400e+02]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "percentage = 0.30\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(features, labels, test_size=percentage, random_state=20176)\n",
    "print features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn import neighbors\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "selector = VarianceThreshold()\n",
    "scaler = StandardScaler()\n",
    "sampler = RandomOverSampler()\n",
    "pca = PCA()\n",
    "classifier = neighbors.KNeighborsClassifier(n_jobs=-1) \n",
    "pipe = Pipeline(steps=[('selector', selector), ('scaler', scaler), ('sampler', sampler), ('pca', pca), ('kNN', classifier)], memory = 'tmp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'> <type 'numpy.ndarray'>\n",
      "(1096, 590) (1096,)\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.94      0.83      0.88       437\n",
      "        1.0       0.12      0.29      0.17        34\n",
      "\n",
      "avg / total       0.88      0.79      0.83       471\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print type(train_data),type(train_labels)\n",
    "print train_data.shape,train_labels.shape\n",
    "pipe.fit(train_data,train_labels)\n",
    "pred = pipe.predict(test_data)\n",
    "print classification_report(test_labels, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "vthreshold = [0, 0.01, 0.005]\n",
    "n_components = [20, 30, 40, 50, 60]\n",
    "k = [1, 5, 10, 20, 30, 40]\n",
    "estimator = GridSearchCV(pipe, dict(selector__threshold=vthreshold, pca__n_components=n_components, kNN__n_neighbors=k), scoring='f1_macro', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(train_data, train_labels)\n",
    "pred = estimator.predict(train_data)\n",
    "print classification_report(train_labels, pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "name": "Meros Deutero.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
